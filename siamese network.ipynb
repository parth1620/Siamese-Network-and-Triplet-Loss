{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1 : Importing libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense,concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2 : Importing the Famous MNIST Handwritten data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 784))/255.\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 784))/255.\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-3 : Visualizing Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplets(examples):\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, 1 + i)\n",
    "        plt.imshow(np.reshape(examples[i], (28, 28)), cmap='binary')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([y_train[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAB2CAYAAADhu9m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAMdklEQVR4nO3de2xVRR7A8d9QxELlobYQpdj6aMRXUClUaaKC8pBFHtGEbgRRgzYqQqKkippIFA1RY1YFo9VsELGuhFhZlLAgKxIDSkEQZJcWH8U2yMtGjI+IyOwfusPM0Hu5t9x7z/T2+/nH3+TXnjN44Ndzp/NQWmsBAISrU9QdAADER6EGgMBRqAEgcBRqAAgchRoAAkehBoDAUag7MKXUKKVUvVLqC6XUg1H3B0DrFPOoOyalVI6INIjIcBFpFpE6Efmr1vo/kXYMwDE6p+Oi+fn5uri4OB2XRhIaGxvlwIEDKkZ6sIh8obX+SkREKfUPERknIjELNc81DMd5rknjuYYh3nNNS6EuLi6WjRs3puPSSEJpaWm8dF8RabLazSJSFu8beK5hOM5zTRrPNQzxnitj1B1Xaz+5jxkHU0rdqZTaqJTauH///gx0C4CPQt1xNYtIP6tdKCK7/S/SWldrrUu11qUFBQUZ6xyAoyjUHVediJQopc5WSnURkQoR+WfEfQLQirSMUSN8WuvDSqlpIvIvEckRkb9rrbdH3C0AraBQd2Ba6+UisjzqfgCIj6EPAAgchRoAAkehBoDAUagBIHAUagAIHIUayEJKqRyl1Gal1LtR9wUnjul56NA2bdrktOfNm2fi1157zclNmTLFxPfee6+Tu/zyy9PQuxMyQ0T+KyI9ou4IThxv1ECWUUoVishfROTVqPuC1KBQA9nnbyJSJSJHou4IUiOhQq2UalRKbVNKbVFKsR8iECil1BgR2ae13nScr2NXxHYkmTHqoVrrA2nrSQR+//13p33w4MGEv9cey/z555+dXH19vYnnz5/v5GbOnGniN99808nl5uaa+MEH3ZOxHn300YT7hti2bNnitK+77jqn/cMPP5hYKXcn2IULF5p46dKlTq6lpSVVXTxR5SIyVik1WkRyRaSHUmqR1nqS/UVa62oRqRYRKS0t5ZinGFavXm3im2++2cl9+OGHJj7//PPT2g+GPoAsorWepbUu1FoXyx87Iv7bL9JofxIt1FpEViqlNiml7mztC/goBQDpkejQR7nWerdSqreIrFJK7dBar7W/IMqPUt98843TPnTokInXrVvn5D766CMTf//9905uyZIlKelPv35H9+P3p3HV1taauHv37k5uwIABJr766qtT0heIbNiwwcQ33nijk/OHu+zhjh493JltXbp0MfGBA+4o4Pr16008cODAmN+XSVrrNSKyJl3XX7vWKQHy3XffmXjChAnpum1G1dXVmTjVR6AlI6E3aq317j//u09EauWPg1EBABlw3EKtlMpTSnX/fywiI0Tk83R3DADwh0SGPvqISO2fHwk7i0iN1npFWnsFADCOW6i11l+JyIDjfV2mbd682cTDhg1zcslMs0uFnJwcpz1nzhwT5+XlOTl7is+ZZ57p5E499VQTp3u6T7axp0h++umnTm7SpKOTHnbvPub83phKSkqcdlVVlYknTpzo5MrLy01sP38RkYceeijhe7Yna9ascdo7d+40cXsdoz5yxF0j9PXXX5vY/12Y1pn7VRzT8wAgcBRqAAhcu909r6ioyMT5+flOLhVDH2VlZU7bHpYQEfnggw9M7E+/mjx58gnfH8mprKw0cU1NTUqu6e+s9+OPP5rYnz5pDwNs27YtJfcPnb+74JAhQyLqSep8++23Tru6utrE/r/r/v37Z6RPIrxRA0DwKNQAEDgKNQAErt2OUZ922mkmfvrpp53csmXLTHzZZZc5uenTp8e85qWXXmri999/38n50+w+//zomp/nn38+gR4jlfzx43ffPXriVLxpU9dcc43THjNmjNO2dzf0p0/af5fi/c4ik9O2ouRPZcsGU6dOjZnzp2tmEm/UABA4CjUABK7dDn3Yxo8f77TtlYr+DnVbt2418auvukfK2R97/aEO38UXX2xiewoP0sfe9D+ZDf9Hjx5tYv+wBn913RNPPGFi/2NwQUGBie2dDv17vvfee07OXikZ4CG4SbH//ezduzfCnqSHv6Ombfjw4RnsiYs3agAIHIUaAAJHoQaAwGXFGLXPP5nD1rNnz5g5e8y6oqLCyXXqxM+0TGtoaHDaTz31lIn9bQLs8eMzzjjDyU2ZMsXEp5xyipPzp+f57bbwDzt+5plnTJyq5e1RWb58uYl/+eWXCHuSOvZYe2NjY8yv69u3bwZ60zqqDwAEjkINAIHLyqGPeGbPnm1if3WbPVXLX5k4YsSIdHYLf/r1119NbE+XFHGnvfnDWwsXLjSxfwhp1B/Rm5qaIr1/KtXX18fMXXTRRRnsSerYf8/27Nnj5OwDPPypvpnEGzUABI5CDQCBo1ADQOA63Bi1vTT8lVdecXL28t477rjDyQ0dOtRp2+Og99xzj5PzlzAjcfZya38ptm3p0qVO2z9xBZk3aNCgqLtg2FsKiIisWLHCxIsWLXJyK1eujHmdRx55xMS9evVKUe+Sxxs1AASOQg0AgetwQx+2c88912kvWLDAxLfddpuTs6d/+e2ffvrJyd1yyy0m9lfJIb777rvPxP4G/Pam/6ENdcQ7LKCjHCTQ0tLSpu/77LPPTOwfRrB69WoTNzc3O7lDhw6Z+I033nBy/nW6du1qYv/g6pNPPtnEv/32m5Pzp3pGhTdqAAgchRoAAkehBoDAdegxat+ECRNMfN555zm5+++/32nbS8xnzZrl5Hbt2mXihx9+2MlFuQNXiOxDaUXcU1z8aY5jx47NSJ/awu6r32/70OT2zh7r9f+clZWVJn7yyScTvqY9Ru2P55900kkm7tatm5O74IILTHz77bc7uYEDBzpt+/cbffr0cXKFhYUm9rcb6N+/f7yuZwxv1AAQOAo1AASOQg0AgWOMOoZLLrnEaS9evNhpL1u2zMS33nqrk3vppZdMvHPnTie3atWqFPUwO/hjgvbc2N69ezu5iRMnZqRPsdhbsNrb5fquvfZapz137tx0dSnjXnzxRRMXFRU5uXXr1rXpmmeddZaJx40b5+QuvPBCE19xxRVtur6vurraae/bt8/E55xzTkrukWq8UQNA4CjUABA4hj4S5O+cNXnyZBNPnTrVydnLUNeuXevk7FNk7ClDOFZubq7TzvRyfHuoQ0Rkzpw5JrYP2hUR6devn4n9qZz+gbrZ4oEHHoi6C21iL0v33XTTTRnsSeJ4owaAwFGoASBwFGoACBxj1DFs3brVaS9ZssRp19XVmdjfGtFmTy8SEbnqqqtS0LuOIYol4/YSdn8c+q233jKxP43s7bffTm/HkBHjx4+Pugut4o0aAAJHoQaAwHXooY/6+nqn/cILL5jY/yi7Z8+ehK/bufPR/63+lLJOnfjZaPN3S7Pb77zzjpN77rnnUn7/Z5991mk//vjjJj548KCTmzRpkon9E3+AdKJqAEDgKNQAEDgKNQAELuvHqP2x5ZqaGhPPmzfPyTU2NrbpHoMGDXLa9qkuIZ9KEgL/lBC77T+76dOnm9g/0eP000838ccff+zkXn/9dRPbp4mIiDQ1NTlte0e4UaNGObm777772D8Asoq/2+WVV14ZUU9cvFEDQOAo1AAQuKwY+ti7d6/T3r59u4mnTZvm5Hbs2NGme5SVlTntqqoqE/ur1JiClxqHDx922vPnzzexv1K0Z8+eJm5oaEj4HkOGDHHaw4YNM/Fjjz2W8HWQHY4cORJ1F1pFRQGAwFGoASBwFGoACFy7GaNuaWlx2pWVlSa2dzwTEfnyyy/bdI/y8nIT+6d0jBw50ml37dq1TfeAy5/+NHjwYBNv2LAh5vf5U/f831PY8vPzTVxRUeHk0rEsHe3X+vXrnbZ/cHVUeKMGgMBRqAEgcEENfXzyySdO29643d6oX0Skubm5Tffo1q2bie2VbiLuisK8vLw2XR/JKSwsdNr2roUvv/yyk7N3totnxowZTvuuu+4ycUlJSbJdBCLHGzUABI5CDQCBo1ADQOCCGqOura2N247FP0D2hhtuMHFOTo6Tmzlzpol79eqVbBeRZvaJOLNnz3Zyfhtoi+uvv95pL168OKKeJI43agAIHIUaAAIX1NDH3Llz47YB4ET5qw1DWX0YD2/UABA4CjUABI5CDQCBo1ADQOAo1AAQOAo1AASOQg0AgaNQA0DgKNQAEDgKNQAETmmtU39RpfaLyK6UXxjJKtJaF6TqYjzXYPBcs1PM55qWQg0ASB2GPgAgcBRqAAgchRoAAkehBoDAUagBIHAUagAIHIUaAAJHoQaAwFGoASBw/wOr8lDI+OESrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x144 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_triplets([x_train[0], x_train[1], x_train[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-4 : Creating batch of triplet [Anchor,Positives,Negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batch_size=256):\n",
    "    x_anchors = np.zeros((batch_size, 784))\n",
    "    x_positives = np.zeros((batch_size, 784))\n",
    "    x_negatives = np.zeros((batch_size, 784))\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        # We need to find an anchor, a positive example and a negative example\n",
    "        random_index = random.randint(0, x_train.shape[0] - 1)\n",
    "        x_anchor = x_train[random_index]\n",
    "        y = y_train[random_index]\n",
    "\n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        \n",
    "        x_positive = x_train[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n",
    "        x_negative = x_train[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "        \n",
    "        x_anchors[i] = x_anchor\n",
    "        x_positives[i] = x_positive\n",
    "        x_negatives[i] = x_negative\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "examples = create_batch(1)\n",
    "plot_triplets(examples)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-5 : Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 64\n",
    "\n",
    "input_img = Input(shape = (784,))\n",
    "l1 = Dense(64,activation = 'relu')(input_img)\n",
    "l2 = Dense(emb_size,activation = 'sigmoid')(l1)\n",
    "\n",
    "embedding_model = Model(input_img,l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5470849  0.5581019  0.5303294  0.42897078 0.5008388  0.49896953\n",
      " 0.5421109  0.5465979  0.5886614  0.50570047 0.48099917 0.53690434\n",
      " 0.5290624  0.52630883 0.49157286 0.53387743 0.34836528 0.5224821\n",
      " 0.55013824 0.5786736  0.59940284 0.59983236 0.48334238 0.4528636\n",
      " 0.55099624 0.51797235 0.5886673  0.40958127 0.53064394 0.534604\n",
      " 0.4747179  0.6166971  0.5809548  0.58763516 0.49495465 0.55083144\n",
      " 0.46090746 0.5669902  0.6158796  0.45422807 0.4744705  0.48243368\n",
      " 0.39773133 0.4625698  0.40386263 0.55074865 0.5680739  0.45313072\n",
      " 0.49444014 0.5964719  0.3846745  0.4585041  0.46120608 0.48489344\n",
      " 0.61778104 0.44632605 0.55523056 0.35045922 0.67026937 0.58681566\n",
      " 0.46421045 0.51758766 0.44203854 0.5393596 ]\n"
     ]
    }
   ],
   "source": [
    "example = np.expand_dims(x_train[0], axis=0)\n",
    "example_emb = embedding_model.predict(example)[0]\n",
    "\n",
    "print(example_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-6 : Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 64)           54400       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192)          0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "                                                                 model[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 54,400\n",
      "Trainable params: 54,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_anchor = Input(shape = (784,))\n",
    "input_positive = Input(shape = (784,))\n",
    "input_negative = Input(shape = (784,))\n",
    "\n",
    "embedding_anchor = embedding_model(input_anchor)\n",
    "embedding_positive = embedding_model(input_positive)\n",
    "embedding_negative = embedding_model(input_negative)\n",
    "\n",
    "output = concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1)\n",
    "\n",
    "siamese_network = Model([input_anchor, input_positive, input_negative], output)\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-7 : Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:emb_size], y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n",
    "    positive_dist = tf.reduce_mean(tf.square(anchor - positive), axis=1)\n",
    "    negative_dist = tf.reduce_mean(tf.square(anchor - negative), axis=1)\n",
    "    return tf.maximum(positive_dist - negative_dist + alpha, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-8 : Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 29 steps\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 24s 817ms/step - loss: 0.1595\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 21s 736ms/step - loss: 0.0731\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.0544\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 27s 925ms/step - loss: 0.0483\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 24s 813ms/step - loss: 0.0439\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 29s 983ms/step - loss: 0.0406\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 25s 854ms/step - loss: 0.0372\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 24s 816ms/step - loss: 0.0347\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 24s 832ms/step - loss: 0.0327\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 24s 842ms/step - loss: 0.0307\n"
     ]
    }
   ],
   "source": [
    "def data_generator(batch_size=256):\n",
    "    while True:\n",
    "        x = create_batch(batch_size)\n",
    "        y = np.zeros((batch_size, 3*emb_size))\n",
    "        yield x, y\n",
    "        \n",
    "batch_size = 2048\n",
    "epochs = 10\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "\n",
    "siamese_network.compile(loss=triplet_loss, optimizer=Adam())\n",
    "\n",
    "_ = siamese_network.fit(\n",
    "    data_generator(batch_size),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs, verbose=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
